{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## PLEASE RUN THE FOLLOWING CODE FOR PRE-PROCESSING THE FILES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Import Python packages \n",
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/workspace\n"
     ]
    }
   ],
   "source": [
    "# checking your current working directory\n",
    "print(os.getcwd())\n",
    "\n",
    "# Get your current folder and subfolder event data\n",
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "# Create a for loop to create a list of files and collect each filepath\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    \n",
    "# join the file path and roots with the subdirectories using glob\n",
    "    file_path_list = glob.glob(os.path.join(root,'*'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# initiating an empty list of rows that will be generated from each file\n",
    "full_data_rows_list = [] \n",
    "    \n",
    "# for every filepath in the file path list \n",
    "for f in file_path_list:\n",
    "\n",
    "# reading csv file \n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        # creating a csv reader object \n",
    "        csvreader = csv.reader(csvfile) \n",
    "        next(csvreader)\n",
    "        \n",
    " # extracting each data row one by one and append it        \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line) \n",
    "            \n",
    "# creating a smaller event data csv file called event_datafile_full csv that will be used to insert data into the \\\n",
    "# Apache Cassandra tables\n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "# check the number of rows in your csv file\n",
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "# Part II. Apache Cassandra code. \n",
    "\n",
    "## Our CSV file titled <font color=red>event_datafile_new.csv</font> is located within the Workspace directory. The event_datafile_new.csv contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# This should make a connection to a Cassandra instance your local machine \n",
    "# (127.0.0.1)\n",
    "\n",
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster(['127.0.0.1'])\n",
    "\n",
    "# To establish connection and begin executing queries, need a session\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Creating a Keyspace named template\n",
    "try:\n",
    "    session.execute(\"\"\"\n",
    "    CREATE KEYSPACE IF NOT EXISTS template \n",
    "    WITH REPLICATION = \n",
    "    { 'class' : 'SimpleStrategy', 'replication_factor' : 1 }\"\"\"\n",
    ")\n",
    "\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Set KEYSPACE to the keyspace specified above\n",
    "try:\n",
    "    session.set_keyspace('template')\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### CREATING OUR SPARKIFY QUERIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Queries to ask the following three questions of the data\n",
    "\n",
    "### 1. Give me the artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "\n",
    "### 2. Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "    \n",
    "\n",
    "### 3. Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "## Processing our event CSV file for our all of our queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## A function to process our INSERT STATEMENTS to any table we choose that has been previously created in Apacha Cassandra \n",
    "## within the session and keyspace initiated above.\n",
    "\n",
    "def insert_with_csv(file, table, query_columns, index_columns, ints, floats):\n",
    "    \"\"\"\n",
    "    It take a file as input plus some query arguments to execute insert statements to an Apache Cassandra table specified.\n",
    "    \n",
    "    file : csv file to read per row.\n",
    "    table : Apache Cassandra table created in keyspace.\n",
    "    query_columns : columns of table in order that wil be used to insert values.\n",
    "    index_columns : index of columns in csv file header that will be used to insert values for each row read in the csv read.\n",
    "    ints: index of values in the insert values that need to be converted to type int.\n",
    "    floats: index of values in the insert values that need to be converted to type float.\n",
    "    \n",
    "    \"\"\"\n",
    "    ## Code to open file and read csv\n",
    "    with open(file, encoding = 'utf8') as f:\n",
    "        csvreader = csv.reader(f)\n",
    "        next(csvreader) # skip header\n",
    "        ## creates a string with the number of placeholders based on the number of columns in the table\n",
    "        values = \"%s, \" * (len(index_columns) - 1) + \"%s\" \n",
    "        for line in csvreader:\n",
    "            ## Assigns the INSERT statements into the `query` variable\n",
    "            query = \"INSERT INTO \" + table + \" \" + query_columns\n",
    "            query = query + \" VALUES \" + \"(\" + values + \")\"\n",
    "            ## Assigns which column element should be assigned for each column in the INSERT statement.\n",
    "            ## For e.g., to INSERT artist_name and user first_name, you would change the index_columns argumetn to [0,1]\n",
    "            row = [line[i] for i in index_columns]\n",
    "            ## Uses the ints argument to cast to int the values in row that needed to be inserted as an int type\n",
    "            row = [row[i] if i not in ints else int(row[i]) for i in range(len(row))]\n",
    "            ## Uses the floats argument to cast to float the values in row needed to be inserted as a float type\n",
    "            row = [row[i] if i not in floats else float(row[i]) for i in range(len(row))]\n",
    "            ## Executes the query\n",
    "            session.execute(query, row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Query 1:  Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "query = \"CREATE TABLE IF NOT EXISTS songs_per_session\"\n",
    "## PRIMARY KEY is set below to focus our query on each session and its children sessionId.\n",
    "query = query + \"(artist varchar, song varchar, length float, sessionId int, itemInSession int, PRIMARY KEY (sessionId, itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## To use insert_with_csv function we define the required arguments that need to be specified \n",
    "## to do insert statements to our Apache Cassandra table.\n",
    "\n",
    "## The file that will be read and each row used to populate the table defined next\n",
    "file = 'event_datafile_new.csv'\n",
    "## Apache Cassandra table created\n",
    "table = 'songs_per_session'\n",
    "## The columns that will be used to form the INSERT INTO query\n",
    "query_columns = '(artist, song, length, sessionId, itemInSession)'\n",
    "## The index_columns will be used to obtain only the columns that are needed to form the query \n",
    "index_columns = [0, 9, 5, 8, 3]\n",
    "## With 'ints' and 'floats' the function knows which values to convert to int/float before submitting the query \n",
    "ints = [3, 4] \n",
    "floats = [2]\n",
    "\n",
    "## We call insert_with_csv that doesn't return an object but execute INSERT INTO queries into the \"songs_per_session\" table.\n",
    "insert_with_csv(file, table, query_columns, index_columns, ints, floats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "#### Do a SELECT to verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      artist                             song      length\n",
      "0  Faithless  Music Matters (Mark Knight Dub)  495.307312\n"
     ]
    }
   ],
   "source": [
    "## States and executes the 1st query. Query 1: Give me the artist, song title and song's length in the music app history that was heard during \\\n",
    "## sessionId = 338, and itemInSession = 4\n",
    "\n",
    "query = \"SELECT artist, song, length FROM songs_per_session WHERE sessionId = 338 AND itemInSession =4\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "## Uses a dataframe to save the query results and display it with column names.\n",
    "df = pd.DataFrame([row for row in rows], columns = ['artist', 'song', 'length'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### New queries can be processed with a CREATE statement and our processing function to speed up results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Query 2: Give me only the following: name of artist, song (sorted by itemInSession) and user (first and last name)\\\n",
    "## for userid = 10, sessionid = 182\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS songs_per_user_per_session\"\n",
    "## PRIMARY KEY is set below in order to sort our results with our first clustering column itemInSession.Hence the need for a composite primary key.\n",
    "query = query + \"(artist varchar, song varchar, first_name text, last_name text, user_id int, sessionId int, itemInSession int, PRIMARY KEY ((user_id, sessionId), itemInSession))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)   \n",
    "\n",
    "## Prepares arguments that will be used in insert_with_csv function to populate 'songs_user_session' table.\n",
    "table = 'songs_per_user_per_session'\n",
    "query_columns = '(artist, song, first_name, last_name, user_id, sessionId, itemInSession)'\n",
    "index_columns = [0, 9, 1, 4, 10, 8, 3]\n",
    "ints = [4, 5, 6]\n",
    "floats = []    \n",
    "\n",
    "## We call insert_with_csv to do INSERT INTO queries from each row on the csv file to the table 'songs_per_user_per_session'.\n",
    "insert_with_csv(file, table, query_columns, index_columns, ints, floats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              artist                                               song  \\\n",
      "0   Down To The Bone                                 Keep On Keepin' On   \n",
      "1       Three Drives                                        Greece 2000   \n",
      "2  Sebastien Tellier                                          Kilometer   \n",
      "3      Lonnie Gordon  Catch You Baby (Steve Pitron & Max Sanna Radio...   \n",
      "\n",
      "  first_name last_name  \n",
      "0     Sylvie      Cruz  \n",
      "1     Sylvie      Cruz  \n",
      "2     Sylvie      Cruz  \n",
      "3     Sylvie      Cruz  \n"
     ]
    }
   ],
   "source": [
    "## Continues stating the SELECT statement for our query 2.\n",
    "query = \"SELECT artist, song, first_name, last_name FROM songs_per_user_per_session WHERE sessionId = 182 AND user_id =10\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df = pd.DataFrame([row for row in rows], columns = ['artist', 'song', 'first_name', 'last_name'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Query 3: Give me every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "query = \"CREATE TABLE IF NOT EXISTS songs_per_user\"\n",
    "## PRIMARY KEY makes sure a song can exist for two or more users. A song name can be repeated this is why the artist column is not needed in the PK \\\n",
    "## since the query only focuses on the song name.\n",
    "query = query + \"(first_name text, last_name text, song varchar, user_id int, PRIMARY KEY (song, user_id))\"\n",
    "try:\n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)                     \n",
    "\n",
    "table = 'songs_per_user'\n",
    "query_columns = '(first_name, last_name, song, user_id)'\n",
    "index_columns = [1, 4, 9, 10]\n",
    "ints = [3]\n",
    "floats = []  \n",
    "\n",
    "insert_with_csv(file, table, query_columns, index_columns, ints, floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        first     last\n",
      "0  Jacqueline    Lynch\n",
      "1       Tegan   Levine\n",
      "2        Sara  Johnson\n"
     ]
    }
   ],
   "source": [
    "## SELECT statement for the last query to 'songs_per_user'. \n",
    "query = \"SELECT first_name, last_name FROM songs_per_user WHERE song = 'All Hands Against His Own'\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "df = pd.DataFrame([row for row in rows], columns = ['first', 'last'])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Drop tables before closing out the sessions\n",
    "query = \"DROP TABLE IF EXISTS songs_per_session\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS songs_per_user_per_session\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "query = \"DROP TABLE IF EXISTS songs_per_user\"\n",
    "try:\n",
    "    rows = session.execute(query)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true
   },
   "source": [
    "### Close the session and cluster connectionÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
